{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text-classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook probar diferentes clasificadores"
      ],
      "metadata": {
        "id": "RWjooeTYAnTf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se pretende explorar diferentes clasificadores variando los hyperparametros, escogiendo el mejor resultado."
      ],
      "metadata": {
        "id": "KcIrGa9gAunO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Importación librerias"
      ],
      "metadata": {
        "id": "EjDjZObJA64d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "AB-3fopyAdC2"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import  MultinomialNB\n",
        "from sklearn.linear_model import SGDClassifier, Perceptron\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "import time\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('popular')"
      ],
      "metadata": {
        "id": "U-SGSteDFvoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk import word_tokenize"
      ],
      "metadata": {
        "id": "sjhvhB_wHYWO"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news = fetch_20newsgroups(subset=\"all\",remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "print(\"Número de articulos: {}\".format(len(news.data)))\n",
        "print(\"Número de categorias: {}\".format(len(news.target_names)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKRgkTfcBOcI",
        "outputId": "953f2438-7302-4cec-bceb-8f4b5c1388d7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de articulos: 18846\n",
            "Número de categorias: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Definción función de entrenamiento  "
      ],
      "metadata": {
        "id": "MmVicDeMB-q7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_fn(classifier, X, Y):\n",
        "  start = time.time()\n",
        "  X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
        "  classifier.fit(X_train, Y_train)\n",
        "  end = time.time()\n",
        "  score = classifier.score(X_test, Y_test)\n",
        "  print(\"Test accuracy: {:.2f}% - Time duration: {:.2f} s\".format(score * 100, (end-start)))\n",
        "  return classifier"
      ],
      "metadata": {
        "id": "PjNpzoH2B-Hx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Preprocesado"
      ],
      "metadata": {
        "id": "7PXKQREVHiwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stemming_tokenizer(text):\n",
        "    stemmer = PorterStemmer()\n",
        "    return [stemmer.stem(w) for w in word_tokenize(text)]"
      ],
      "metadata": {
        "id": "FGu3xG88Hh96"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Construcción de clasificadores"
      ],
      "metadata": {
        "id": "IBdlxOaPEPD6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.1. Multinominal Naive Bayes Classifier"
      ],
      "metadata": {
        "id": "iF8aicupEXEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for alpha in [1, 0.1, 0.01, 0.001, 0.0001]:\n",
        "  NBclf = Pipeline(\n",
        "      [('vectorizer', TfidfVectorizer(stop_words=stopwords.words('english')+ list(string.punctuation))),\n",
        "      ('classifier', MultinomialNB(alpha=alpha))]\n",
        "  )\n",
        "\n",
        "  train_fn(NBclf, news.data, news.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JesfWH5YBxKc",
        "outputId": "c72153ac-0ed0-4588-c865-ce2eac155ab5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 71.27% - Time duration: 2.84 s\n",
            "Test accuracy: 76.02% - Time duration: 2.79 s\n",
            "Test accuracy: 75.86% - Time duration: 2.87 s\n",
            "Test accuracy: 74.67% - Time duration: 2.86 s\n",
            "Test accuracy: 73.55% - Time duration: 2.84 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se escoge el mejor desempeño y se realiza prueba eliminado signo de puntuación y stemming."
      ],
      "metadata": {
        "id": "0Y73u9n6IOzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NBclf = Pipeline(\n",
        "    [('vectorizer', TfidfVectorizer(tokenizer=stemming_tokenizer,stop_words=stopwords.words('english') + list(string.punctuation))),\n",
        "    ('classifier', MultinomialNB(alpha=0.1))]\n",
        ")\n",
        "train_fn(NBclf, news.data, news.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brZd2_m6FHQO",
        "outputId": "3db297f8-9c36-4279-e1b8-d57156b1b9b7"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", '``', 'abov', 'ani', 'becaus', 'befor', 'could', 'doe', 'dure', 'ha', 'hi', 'might', 'must', \"n't\", 'need', 'onc', 'onli', 'ourselv', 'sha', 'themselv', 'thi', 'veri', 'wa', 'whi', 'wo', 'would', 'yourselv'] not in stop_words.\n",
            "  % sorted(inconsistent)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 73.98% - Time duration: 87.26 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vectorizer',\n",
              "                 TfidfVectorizer(stop_words=['i', 'me', 'my', 'myself', 'we',\n",
              "                                             'our', 'ours', 'ourselves', 'you',\n",
              "                                             \"you're\", \"you've\", \"you'll\",\n",
              "                                             \"you'd\", 'your', 'yours',\n",
              "                                             'yourself', 'yourselves', 'he',\n",
              "                                             'him', 'his', 'himself', 'she',\n",
              "                                             \"she's\", 'her', 'hers', 'herself',\n",
              "                                             'it', \"it's\", 'its', 'itself', ...],\n",
              "                                 tokenizer=<function stemming_tokenizer at 0x7f61810e57a0>)),\n",
              "                ('classifier', MultinomialNB(alpha=0.1))])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.2. Support Vector Classification con stochatic gradient descent"
      ],
      "metadata": {
        "id": "f05ulzFmJHKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for alpha in [1, 0.1, 0.01, 0.001, 0.0001, 0.00001]:  \n",
        "  SVMclf1 = Pipeline(\n",
        "      [('vectorizer',TfidfVectorizer(stop_words=stopwords.words('english') + list(string.punctuation))), \n",
        "      ('classifier', SGDClassifier(alpha=alpha))]\n",
        "  )\n",
        "\n",
        "  train_fn(SVMclf1, news.data, news.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJZfEqcSIuYK",
        "outputId": "55a4a9c9-d194-4c70-96f1-338353146d24"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 5.07% - Time duration: 5.81 s\n",
            "Test accuracy: 45.86% - Time duration: 6.73 s\n",
            "Test accuracy: 73.08% - Time duration: 3.98 s\n",
            "Test accuracy: 73.32% - Time duration: 3.89 s\n",
            "Test accuracy: 75.46% - Time duration: 4.58 s\n",
            "Test accuracy: 74.91% - Time duration: 4.56 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se escoge el mejor desempeño y se realiza prueba eliminado signo de puntuación y stemming."
      ],
      "metadata": {
        "id": "ThuTi9rHNYPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SVMclf1 = Pipeline(\n",
        "    [('vectorizer',TfidfVectorizer(tokenizer=stemming_tokenizer,stop_words=stopwords.words('english') + list(string.punctuation))), \n",
        "    ('classifier', SGDClassifier(alpha=0.0001))]\n",
        "  )\n",
        "\n",
        "train_fn(SVMclf1, news.data, news.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcpMNTR0J0Bp",
        "outputId": "2e46e108-e979-49e7-b717-558c9b291da6"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", '``', 'abov', 'ani', 'becaus', 'befor', 'could', 'doe', 'dure', 'ha', 'hi', 'might', 'must', \"n't\", 'need', 'onc', 'onli', 'ourselv', 'sha', 'themselv', 'thi', 'veri', 'wa', 'whi', 'wo', 'would', 'yourselv'] not in stop_words.\n",
            "  % sorted(inconsistent)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 75.65% - Time duration: 89.95 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vectorizer',\n",
              "                 TfidfVectorizer(stop_words=['i', 'me', 'my', 'myself', 'we',\n",
              "                                             'our', 'ours', 'ourselves', 'you',\n",
              "                                             \"you're\", \"you've\", \"you'll\",\n",
              "                                             \"you'd\", 'your', 'yours',\n",
              "                                             'yourself', 'yourselves', 'he',\n",
              "                                             'him', 'his', 'himself', 'she',\n",
              "                                             \"she's\", 'her', 'hers', 'herself',\n",
              "                                             'it', \"it's\", 'its', 'itself', ...],\n",
              "                                 tokenizer=<function stemming_tokenizer at 0x7f61810e57a0>)),\n",
              "                ('classifier', SGDClassifier())])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.3. Support Vector Classification con liner SVC"
      ],
      "metadata": {
        "id": "CSxjUK-tNaK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SVMclf2 = Pipeline(\n",
        "    [('vectorizer',TfidfVectorizer(stop_words=stopwords.words('english') + list(string.punctuation))), \n",
        "    ('classifier', LinearSVC())]\n",
        ")\n",
        "\n",
        "train_fn(SVMclf2, news.data, news.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0PWzhVGME42",
        "outputId": "b24974b8-0083-4bdd-8025-ca4f4a3747db"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 75.92% - Time duration: 5.22 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vectorizer',\n",
              "                 TfidfVectorizer(stop_words=['i', 'me', 'my', 'myself', 'we',\n",
              "                                             'our', 'ours', 'ourselves', 'you',\n",
              "                                             \"you're\", \"you've\", \"you'll\",\n",
              "                                             \"you'd\", 'your', 'yours',\n",
              "                                             'yourself', 'yourselves', 'he',\n",
              "                                             'him', 'his', 'himself', 'she',\n",
              "                                             \"she's\", 'her', 'hers', 'herself',\n",
              "                                             'it', \"it's\", 'its', 'itself', ...])),\n",
              "                ('classifier', LinearSVC())])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con stemming."
      ],
      "metadata": {
        "id": "vvQiI8ukOY5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SVMclf2 = Pipeline(\n",
        "    [('vectorizer',TfidfVectorizer(tokenizer=stemming_tokenizer,stop_words=stopwords.words('english') + list(string.punctuation))), \n",
        "    ('classifier', LinearSVC())]\n",
        ")\n",
        "\n",
        "train_fn(SVMclf2, news.data, news.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTAYkT3FOYa1",
        "outputId": "b25f3e14-25fa-4835-cec6-f05a8d1024ef"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", '``', 'abov', 'ani', 'becaus', 'befor', 'could', 'doe', 'dure', 'ha', 'hi', 'might', 'must', \"n't\", 'need', 'onc', 'onli', 'ourselv', 'sha', 'themselv', 'thi', 'veri', 'wa', 'whi', 'wo', 'would', 'yourselv'] not in stop_words.\n",
            "  % sorted(inconsistent)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 76.05% - Time duration: 90.04 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vectorizer',\n",
              "                 TfidfVectorizer(stop_words=['i', 'me', 'my', 'myself', 'we',\n",
              "                                             'our', 'ours', 'ourselves', 'you',\n",
              "                                             \"you're\", \"you've\", \"you'll\",\n",
              "                                             \"you'd\", 'your', 'yours',\n",
              "                                             'yourself', 'yourselves', 'he',\n",
              "                                             'him', 'his', 'himself', 'she',\n",
              "                                             \"she's\", 'her', 'hers', 'herself',\n",
              "                                             'it', \"it's\", 'its', 'itself', ...],\n",
              "                                 tokenizer=<function stemming_tokenizer at 0x7f61810e57a0>)),\n",
              "                ('classifier', LinearSVC())])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.4. Perceptron"
      ],
      "metadata": {
        "id": "JVouH3sqRwni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for alpha in [1, 0.1, 0.01, 0.001, 0.0001, 0.00001]:  \n",
        "  perclf = Pipeline(\n",
        "      [('vectorizer',TfidfVectorizer(stop_words=stopwords.words('english') + list(string.punctuation))), \n",
        "      ('classifier', Perceptron(alpha=alpha))]\n",
        "  )\n",
        "\n",
        "  train_fn(perclf, news.data, news.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AM188sjFOMK6",
        "outputId": "54ed3b7f-ce2d-4cdc-e357-550c4fe4b320"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 70.50% - Time duration: 4.06 s\n",
            "Test accuracy: 70.53% - Time duration: 3.93 s\n",
            "Test accuracy: 69.76% - Time duration: 3.90 s\n",
            "Test accuracy: 71.35% - Time duration: 3.98 s\n",
            "Test accuracy: 70.53% - Time duration: 3.90 s\n",
            "Test accuracy: 70.27% - Time duration: 3.97 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perclf = Pipeline(\n",
        "    [('vectorizer',TfidfVectorizer(stop_words=stopwords.words('english') + list(string.punctuation))), \n",
        "    ('classifier', Perceptron(alpha=0.001))]\n",
        ")\n",
        "\n",
        "train_fn(perclf, news.data, news.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ijh0cvY6SE0w",
        "outputId": "5043adee-fe9e-4e94-b304-2eaaf5353239"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 71.01% - Time duration: 3.88 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vectorizer',\n",
              "                 TfidfVectorizer(stop_words=['i', 'me', 'my', 'myself', 'we',\n",
              "                                             'our', 'ours', 'ourselves', 'you',\n",
              "                                             \"you're\", \"you've\", \"you'll\",\n",
              "                                             \"you'd\", 'your', 'yours',\n",
              "                                             'yourself', 'yourselves', 'he',\n",
              "                                             'him', 'his', 'himself', 'she',\n",
              "                                             \"she's\", 'her', 'hers', 'herself',\n",
              "                                             'it', \"it's\", 'its', 'itself', ...])),\n",
              "                ('classifier', Perceptron(alpha=0.001))])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kGG3e9GxSVYz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}